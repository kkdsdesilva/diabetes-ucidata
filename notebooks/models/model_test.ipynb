{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(cur_dir+\"/../../\")\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 09:04:45.490642: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-14 09:04:45.651432: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 09:04:45.651544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 09:04:45.674776: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 09:04:45.734056: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-14 09:04:45.735259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 09:04:46.997627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from src.data.load_data import load_data\n",
    "from src.features.labeling import label_encode, one_hot_encode, label_and_one_hot_encode\n",
    "from src.features.selection import select_features\n",
    "from src.data.data_scaling import standardize_data, normalize_data\n",
    "from src.data.split_data import split_data\n",
    "from src.models.Logistic import train_Logistic\n",
    "from src.models.NN import train_NN\n",
    "from src.models.evaluate import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df_wo = load_data()\n",
    "df_w = load_data(weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasi/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "# label encode readmitted column\n",
    "df_wo = label_encode(df_wo, \"readmitted\", {'NO': 0, '>30': 1, '<30': 1})\n",
    "\n",
    "# one hot encode the categorical columns\n",
    "df_wo = one_hot_encode(df_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train_wo, X_test_wo, y_train_wo, y_test_wo = split_data(df_wo, \"readmitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Data Standardized\n",
      "--------------------\n",
      "--------------------\n",
      "Data Standardized\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# standardize the data\n",
    "X_train_wo, X_test_wo = standardize_data(X_train_wo), standardize_data(X_test_wo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config_1 = [(32, 'relu')]\n",
    "input_dim, n_ini, epochs, batch_size, validation_split, learning_rate = 47, 16, 100, 32, 0.2, 0.001 # int(df_wo.shape[-1]), \n",
    "\n",
    "nn_model = train_NN(config_1, X_train_wo, y_train_wo, input_dim, n_ini, epochs, batch_size, validation_split, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 30)                73950     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74271 (290.12 KB)\n",
      "Trainable params: 74271 (290.12 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config_1 = [(32, 'relu')]\n",
    "input_dim, n_ini, epochs, batch_size, validation_split, learning_rate = int(df_wo.shape[-1])-1, 16, 100, 32, 0.2, 0.001 # int(df_wo.shape[-1]), \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(30, input_dim=input_dim, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "  #tf.keras.layers.Lambda(lambda x: x * 400)\n",
    "])\n",
    "\n",
    " # Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 09:13:36.714110: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1404204032 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.6319 - accuracy: 0.6374\n",
      "Epoch 2/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.6140 - accuracy: 0.6529\n",
      "Epoch 3/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.6049 - accuracy: 0.6621\n",
      "Epoch 4/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5956 - accuracy: 0.6710\n",
      "Epoch 5/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5850 - accuracy: 0.6820\n",
      "Epoch 6/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5755 - accuracy: 0.6891\n",
      "Epoch 7/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5649 - accuracy: 0.6968\n",
      "Epoch 8/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.5555 - accuracy: 0.7065\n",
      "Epoch 9/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.5458 - accuracy: 0.7141\n",
      "Epoch 10/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5366 - accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5270 - accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5196 - accuracy: 0.7314\n",
      "Epoch 13/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5108 - accuracy: 0.7388\n",
      "Epoch 14/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.5037 - accuracy: 0.7443\n",
      "Epoch 15/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4962 - accuracy: 0.7485\n",
      "Epoch 16/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4901 - accuracy: 0.7537\n",
      "Epoch 17/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4838 - accuracy: 0.7566\n",
      "Epoch 18/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4770 - accuracy: 0.7592\n",
      "Epoch 19/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4716 - accuracy: 0.7655\n",
      "Epoch 20/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4672 - accuracy: 0.7662\n",
      "Epoch 21/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4629 - accuracy: 0.7679\n",
      "Epoch 22/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4583 - accuracy: 0.7725\n",
      "Epoch 23/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4535 - accuracy: 0.7752\n",
      "Epoch 24/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4498 - accuracy: 0.7769\n",
      "Epoch 25/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4455 - accuracy: 0.7801\n",
      "Epoch 26/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4427 - accuracy: 0.7804\n",
      "Epoch 27/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4384 - accuracy: 0.7830\n",
      "Epoch 28/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4361 - accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4331 - accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4294 - accuracy: 0.7885\n",
      "Epoch 31/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4273 - accuracy: 0.7884\n",
      "Epoch 32/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4234 - accuracy: 0.7919\n",
      "Epoch 33/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4209 - accuracy: 0.7934\n",
      "Epoch 34/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.4185 - accuracy: 0.7935\n",
      "Epoch 35/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4164 - accuracy: 0.7953\n",
      "Epoch 36/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4138 - accuracy: 0.7975\n",
      "Epoch 37/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4119 - accuracy: 0.7977\n",
      "Epoch 38/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4091 - accuracy: 0.7988\n",
      "Epoch 39/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.4067 - accuracy: 0.8007\n",
      "Epoch 40/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.4046 - accuracy: 0.8013\n",
      "Epoch 41/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4037 - accuracy: 0.8011\n",
      "Epoch 42/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.4018 - accuracy: 0.8017\n",
      "Epoch 43/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3995 - accuracy: 0.8042\n",
      "Epoch 44/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3980 - accuracy: 0.8037\n",
      "Epoch 45/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3961 - accuracy: 0.8049\n",
      "Epoch 46/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3940 - accuracy: 0.8064\n",
      "Epoch 47/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3934 - accuracy: 0.8063\n",
      "Epoch 48/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3914 - accuracy: 0.8077\n",
      "Epoch 49/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3896 - accuracy: 0.8095\n",
      "Epoch 50/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3883 - accuracy: 0.8089\n",
      "Epoch 51/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3864 - accuracy: 0.8110\n",
      "Epoch 52/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3857 - accuracy: 0.8115\n",
      "Epoch 53/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3836 - accuracy: 0.8126\n",
      "Epoch 54/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3829 - accuracy: 0.8125\n",
      "Epoch 55/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3814 - accuracy: 0.8140\n",
      "Epoch 56/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3796 - accuracy: 0.8149\n",
      "Epoch 57/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3786 - accuracy: 0.8149\n",
      "Epoch 58/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3774 - accuracy: 0.8144\n",
      "Epoch 59/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3764 - accuracy: 0.8142\n",
      "Epoch 60/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3749 - accuracy: 0.8174\n",
      "Epoch 61/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3737 - accuracy: 0.8164\n",
      "Epoch 62/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3738 - accuracy: 0.8164\n",
      "Epoch 63/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3723 - accuracy: 0.8176\n",
      "Epoch 64/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3705 - accuracy: 0.8193\n",
      "Epoch 65/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3700 - accuracy: 0.8184\n",
      "Epoch 66/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3687 - accuracy: 0.8190\n",
      "Epoch 67/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3680 - accuracy: 0.8194\n",
      "Epoch 68/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3661 - accuracy: 0.8202\n",
      "Epoch 69/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3658 - accuracy: 0.8200\n",
      "Epoch 70/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3656 - accuracy: 0.8211\n",
      "Epoch 71/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3642 - accuracy: 0.8215\n",
      "Epoch 72/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3628 - accuracy: 0.8230\n",
      "Epoch 73/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3621 - accuracy: 0.8225\n",
      "Epoch 74/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3621 - accuracy: 0.8222\n",
      "Epoch 75/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3599 - accuracy: 0.8245\n",
      "Epoch 76/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3597 - accuracy: 0.8234\n",
      "Epoch 77/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3590 - accuracy: 0.8242\n",
      "Epoch 78/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3590 - accuracy: 0.8241\n",
      "Epoch 79/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3581 - accuracy: 0.8243\n",
      "Epoch 80/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3568 - accuracy: 0.8256\n",
      "Epoch 81/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3559 - accuracy: 0.8250\n",
      "Epoch 82/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3555 - accuracy: 0.8253\n",
      "Epoch 83/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3543 - accuracy: 0.8259\n",
      "Epoch 84/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3537 - accuracy: 0.8266\n",
      "Epoch 85/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3537 - accuracy: 0.8273\n",
      "Epoch 86/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3524 - accuracy: 0.8269\n",
      "Epoch 87/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3513 - accuracy: 0.8287\n",
      "Epoch 88/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3513 - accuracy: 0.8283\n",
      "Epoch 89/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3504 - accuracy: 0.8285\n",
      "Epoch 90/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3498 - accuracy: 0.8294\n",
      "Epoch 91/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3494 - accuracy: 0.8289\n",
      "Epoch 92/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3492 - accuracy: 0.8284\n",
      "Epoch 93/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3474 - accuracy: 0.8288\n",
      "Epoch 94/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3484 - accuracy: 0.8288\n",
      "Epoch 95/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3476 - accuracy: 0.8288\n",
      "Epoch 96/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3469 - accuracy: 0.8304\n",
      "Epoch 97/100\n",
      "7124/7124 [==============================] - 10s 1ms/step - loss: 0.3463 - accuracy: 0.8297\n",
      "Epoch 98/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.3460 - accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "7124/7124 [==============================] - 11s 1ms/step - loss: 0.3441 - accuracy: 0.8318\n",
      "Epoch 100/100\n",
      "7124/7124 [==============================] - 11s 2ms/step - loss: 0.3445 - accuracy: 0.8311\n"
     ]
    }
   ],
   "source": [
    "# Set the training parameters\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=learning_rate))\n",
    "\n",
    "# Train the model\n",
    "#model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "history = model.fit(X_train_wo, y_train_wo, batch_size=10, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Logistic Regression model\n",
    "logreg= train_Logistic(X_train_wo, y_train_wo, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'feature_importance_logreg' from 'src.features' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68159/825132671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_importance_logreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_importance_logreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_wo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'feature_importance_logreg' from 'src.features' (unknown location)"
     ]
    }
   ],
   "source": [
    "from src.features.feature_importance import feature_importance_logreg\n",
    "imp = feature_importance_logreg(logreg, X_train_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_wo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_importance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pick_top_k_features\n\u001b[0;32m----> 2\u001b[0m pick_top_k_features(\u001b[43mX_train_wo\u001b[49m, imp, \u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_wo' is not defined"
     ]
    }
   ],
   "source": [
    "from src.features.feature_importance import pick_top_k_features\n",
    "pick_top_k_features(X_train_wo, imp, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.DecisionTree import train_DecisionTree\n",
    "from src.features.feature_importance import feature_importance_other, pick_top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasi/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "data = label_and_one_hot_encode(load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_DecisionTree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68159/2976565444.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train Decision Tree model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_DecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_DecisionTree' is not defined"
     ]
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = split_data(data, \"readmitted\")\n",
    "\n",
    "# train Decision Tree model\n",
    "dtree = train_DecisionTree(X_train, y_train, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6564939075748217\n",
      "Test accuracy:  0.627644939403865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6564939075748217, 0.627644939403865)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(dtree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "imp = feature_importance_other(dtree, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_inpatient</th>\n",
       "      <td>0.380512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <td>0.172923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_diagnoses</th>\n",
       "      <td>0.055411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_emergency</th>\n",
       "      <td>0.035900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_source_id</th>\n",
       "      <td>0.032473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_155</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_156</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_157</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_162</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_580</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2419 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance\n",
       "number_inpatient            0.380512\n",
       "discharge_disposition_id    0.172923\n",
       "number_diagnoses            0.055411\n",
       "number_emergency            0.035900\n",
       "admission_source_id         0.032473\n",
       "...                              ...\n",
       "diag_2_155                  0.000000\n",
       "diag_2_156                  0.000000\n",
       "diag_2_157                  0.000000\n",
       "diag_2_162                  0.000000\n",
       "diag_2_580                  0.000000\n",
       "\n",
       "[2419 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = label_and_one_hot_encode(load_data())\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(data, \"readmitted\")\n",
    "\n",
    "# pick top k features\n",
    "X_train = pick_top_k_features(X_train, imp, 1000)\n",
    "X_test = pick_top_k_features(X_test, imp, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = train_DecisionTree(X_train, y_train, max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7086725812791286\n",
      "Test accuracy:  0.6199148378643957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7086725812791286, 0.6199148378643957)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(dtree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-diabetes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
